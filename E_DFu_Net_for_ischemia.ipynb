{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2OeRqyzbXmvBFcnxaVIMo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoufAlmufadi/-E-DFu-Net/blob/main/E_DFu_Net_for_ischemia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkTl_4EAMvqK"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "from keras import optimizers\n",
        "from keras.layers import Input, Lambda, Dense, Flatten, Dropout\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras import metrics\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "import os\n",
        "from imutils import paths\n",
        "from cv2 import imread\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils import shuffle\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x"
      ],
      "metadata": {
        "id": "I27IjHI5M8jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q -U keras-tuner"
      ],
      "metadata": {
        "id": "9-ZaQ_ASM8mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install plot_keras_history"
      ],
      "metadata": {
        "id": "FT7L88j1M8pB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plot_keras_history import show_history, plot_history\n"
      ],
      "metadata": {
        "id": "Kiy8FFTZM8rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = [224, 224]"
      ],
      "metadata": {
        "id": "6Vn1GilvM8uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "umQccXQ-M8wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "\n",
        "train_images = []\n",
        "train_labels = []\n",
        "\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "val_images = []\n",
        "\n",
        "for directory_path in glob.glob(\"/content/drive/My Drive/datasets/ischaemia_12000agusplit/train/*\"):\n",
        "    label = os.path.split(directory_path)\n",
        "    print(label)\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        print(img_path)\n",
        "        image=tf.keras.preprocessing.image.load_img(img_path, color_mode='rgb',\n",
        "        target_size= (224,224))\n",
        "        image=np.array(image)\n",
        "        train_images.append(image)\n",
        "        train_labels.append(label)\n",
        "\n",
        "for directory_path1 in glob.glob(\"/content/drive/My Drive/datasets/ischaemia_12000agusplit/test/*\"):\n",
        "    label1 = os.path.split(directory_path1)\n",
        "    print(label1)\n",
        "    for img_path1 in glob.glob(os.path.join(directory_path1, \"*.jpg\")):\n",
        "        print(img_path1)\n",
        "        image1=tf.keras.preprocessing.image.load_img(img_path1, color_mode='rgb',\n",
        "        target_size= (224,224))\n",
        "        image1=np.array(image1)\n",
        "        test_images.append(image1)\n",
        "        test_labels.append(label1)\n",
        "\n",
        "for directory_path in glob.glob(\"/content/drive/My Drive/datasets/ischaemia_12000agusplit/val/*\"):\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        print(img_path)\n",
        "        image=tf.keras.preprocessing.image.load_img(img_path, color_mode='rgb',\n",
        "        target_size= (224,224))\n",
        "        image=np.array(image)\n",
        "        val_images.append(image)\n",
        "\n",
        "\n",
        "\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "\n",
        "test_images = np.array(test_images)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "val_images = np.array(val_images)\n",
        "\n",
        "print(test_labels.shape)\n",
        "print(train_labels.shape)\n",
        "\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)\n",
        "print(val_images.shape)\n"
      ],
      "metadata": {
        "id": "yByEiuReM8zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "EfficientNetB0 = EfficientNetB0(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n"
      ],
      "metadata": {
        "id": "bLvmTdmxM82K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EfficientNetB0.input\n"
      ],
      "metadata": {
        "id": "QabCz1MhM84x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in EfficientNetB0.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "G03R4SYgM87C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "x = Flatten()(EfficientNetB0.output)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x=BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001)(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x=BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001)(x)\n",
        "x=Dense(256, kernel_regularizer= tensorflow.keras.regularizers.l2(l= 0.016), activity_regularizer= tensorflow.keras.regularizers.l1(0.006),bias_regularizer= tensorflow.keras.regularizers.l1(0.006), activation= 'relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x=Dense(128, kernel_regularizer= tensorflow.keras.regularizers.l2(l= 0.016), activity_regularizer= tensorflow.keras.regularizers.l1(0.006),bias_regularizer= tensorflow.keras.regularizers.l1(0.006), activation= 'relu')(x)\n",
        "x=Dropout(rate= 0.45, seed= 123)(x)\n",
        "prediction = Dense(2,activation='sigmoid')(x)\n",
        "model = Model(inputs=EfficientNetB0.input, outputs=prediction)"
      ],
      "metadata": {
        "id": "cx6gRx4hN-sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator()\n",
        "test_datagen = ImageDataGenerator()\n",
        "val_datagen = ImageDataGenerator()"
      ],
      "metadata": {
        "id": "Oe6jJ-bgN-vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = train_datagen.flow_from_directory('/content/drive/My Drive/datasets/ischaemia_12000agusplit/train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "metadata": {
        "id": "pPniWq1QN-yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a generator for the test data without augmentation\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/My Drive/datasets/ischaemia_12000agusplit/test',\n",
        "                                                  target_size=(224, 224),\n",
        "                                                  batch_size=32,\n",
        "                                                  class_mode='categorical' )"
      ],
      "metadata": {
        "id": "nqAp1p7IN-1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_set = val_datagen.flow_from_directory('/content/drive/My Drive/datasets/ischaemia_12000agusplit/val',\n",
        "                                                  target_size=(224, 224),\n",
        "                                                  batch_size=32,\n",
        "                                                  class_mode='categorical' )"
      ],
      "metadata": {
        "id": "UVpLXz5LN-4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adamax\n",
        "model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "metadata": {
        "id": "8YbzCg6IOZq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss',verbose=1, patience=20)"
      ],
      "metadata": {
        "id": "OF3tWMJgO70e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "\n",
        "#starting time\n",
        "start = time.time()\n",
        "\n",
        "batch_size = 32\n",
        "#batch_size = 64\n",
        "#batch_size = 128\n",
        "hist = model.fit(train_set, steps_per_epoch = train_set.samples//batch_size,\n",
        "                 validation_data = val_set,validation_steps = val_set.samples//batch_size,\n",
        "                 epochs = 100,callbacks=[es]\n",
        "                 )\n",
        "# end time\n",
        "end = time.time()\n",
        "\n",
        "# total time taken\n",
        "print(\"Execution time of the program is- \", end-start)"
      ],
      "metadata": {
        "id": "CXNl54DQO740"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the loss\n",
        "plt.plot(hist.history['loss'], label='train loss',marker='o')\n",
        "plt.plot(hist.history['val_loss'], label='val loss',marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lCQhS2LgO77S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# plot the loss\n",
        "plt.plot(hist.history['accuracy'], label='train accuracy',marker='o')\n",
        "plt.plot(hist.history['val_accuracy'], label='val accuracy',marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g4Qh_o5eO79e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train_labels[:, 1]\n",
        "test_labels = test_labels[:, 1]"
      ],
      "metadata": {
        "id": "EQmHSU-hO8AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "label_mapping = {'Aug-Negative': 0, 'Aug-Positive': 1}\n",
        "train_labels = np.array([label_mapping[label] for label in train_labels])\n",
        "test_labels = np.array([label_mapping[label] for label in test_labels])"
      ],
      "metadata": {
        "id": "Pvx-qzqcPJcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Make predictions on the training data\n",
        "train_pred_probs = model.predict(train_images)  # Use the original training data\n",
        "train_pred_labels = np.argmax(train_pred_probs, axis=1)\n",
        "\n",
        "# Make predictions on the test data\n",
        "test_pred_probs = model.predict(test_images)\n",
        "test_pred_labels = np.argmax(test_pred_probs, axis=1)\n",
        "\n",
        "# Ensure that train_labels and test_labels are correctly shaped\n",
        "# They should be one-dimensional arrays if not already\n",
        "train_labels = np.squeeze(train_labels)\n",
        "test_labels = np.squeeze(test_labels)\n",
        "\n",
        "# Calculate the accuracy scores\n",
        "train_accuracy = metrics.accuracy_score(train_labels, train_pred_labels)\n",
        "test_accuracy = metrics.accuracy_score(test_labels, test_pred_labels)\n",
        "\n",
        "print(\"\\nTraining Accuracy Score:\", train_accuracy * 100)\n",
        "print(\"\\nTesting Accuracy Score:\", test_accuracy * 100)"
      ],
      "metadata": {
        "id": "0mHJd8YxPJfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_train=model.predict(train_images)\n",
        "feat_train=feat_train.reshape(feat_train.shape[0], -1)\n",
        "\n",
        "feat_test=model.predict(test_images)\n",
        "feat_test=feat_test.reshape(feat_test.shape[0], -1)"
      ],
      "metadata": {
        "id": "SBRszBzpPJi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_pred_labels)\n",
        "\n",
        "print('Accuracy: %f' % accuracy)\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(test_labels, test_pred_labels)\n",
        "\n",
        "print('Precision: %f' %precision)\n",
        "\n",
        "# recall: tp / (tp + fn)\n",
        "\n",
        "recall = recall_score(test_labels, test_pred_labels)\n",
        "\n",
        "print('Recall: %f' % recall)\n",
        "\n",
        "\n",
        "Specificity = recall_score(test_labels, test_pred_labels, pos_label= 0)\n",
        "\n",
        "print('Specificity: %f' % Specificity)\n",
        "\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "\n",
        "f1 = f1_score(test_labels, test_pred_labels)\n",
        "\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "roc_auc = roc_auc_score(test_labels, test_pred_labels)\n",
        "\n",
        "print('roc_auc: %f' % roc_auc)"
      ],
      "metadata": {
        "id": "CyThkKgBPJln"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}